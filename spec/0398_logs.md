# Spec 0398: Logs & Analytics Feature (Enhanced)

## Overview

This specification describes the enhanced Logs & Analytics feature for Localbase, modeled after Supabase's latest logs explorer interface. The feature provides comprehensive logging, filtering, analytics, and visualization for all Localbase services including API Gateway, Postgres (with severity levels), Auth, Storage, Realtime, Edge Functions, and more.

## Background

Supabase's Logs & Analytics feature enables users to track and analyze log events from various services. The system is powered by a logging pipeline that routes logs to an analytics backend. Key features include:

- Multiple log sources (edge_logs, postgres_logs, auth_logs, storage_logs, etc.)
- Severity level filtering for Postgres logs (DEBUG, INFO, WARNING, ERROR, FATAL, PANIC)
- Advanced filtering with regex support
- Time-series histogram visualization
- Saved queries and templates
- Request tracing via request_id

For Localbase, we implement a PostgreSQL-backed logging system optimized for local development and production use.

## Goals

1. Provide comprehensive logging for all Localbase services
2. Match Supabase's Logs UI/UX 100%
3. Support real-time log ingestion and querying
4. Enable filtering by service, status, method, severity, time range
5. Support regex pattern matching for advanced searches
6. Provide histogram visualization with color-coded status/severity
7. Support saved queries and templates
8. Enable request tracing across services

## Non-Goals

1. BigQuery integration (PostgreSQL-only for simplicity)
2. Log drains to external services (future enhancement)
3. Real-time WebSocket streaming (future enhancement)

## Design

### Architecture

```
┌──────────────────────────────────────────────────────────────────┐
│                         Localbase Server                          │
├──────────────────────────────────────────────────────────────────┤
│                                                                   │
│  ┌─────────────┐   ┌─────────────┐   ┌─────────────┐            │
│  │   Auth      │   │  Storage    │   │  Functions  │   ...      │
│  │   Handler   │   │  Handler    │   │   Handler   │            │
│  └──────┬──────┘   └──────┬──────┘   └──────┬──────┘            │
│         │                 │                 │                    │
│         └────────────────┬┴─────────────────┘                    │
│                          │                                        │
│                          ▼                                        │
│  ┌───────────────────────────────────────────────────────────┐  │
│  │                   Logging Middleware                        │  │
│  │   - Captures HTTP request/response metadata                 │  │
│  │   - Extracts user info, API key, headers                   │  │
│  │   - Writes to LogsStore asynchronously                     │  │
│  └───────────────────────────────────────────────────────────┘  │
│                          │                                        │
│                          ▼                                        │
│  ┌───────────────────────────────────────────────────────────┐  │
│  │                      LogsStore                              │  │
│  │   PostgreSQL: analytics.logs table                          │  │
│  │   - Partitioned by timestamp                                │  │
│  │   - Indexed for fast querying                               │  │
│  └───────────────────────────────────────────────────────────┘  │
│                                                                   │
└──────────────────────────────────────────────────────────────────┘
```

### Log Collections

Based on Supabase's design, we support the following log collections:

| Source ID | Display Name | Description |
|-----------|--------------|-------------|
| `edge` | API Gateway | HTTP request/response logs from the API gateway |
| `postgres` | Postgres | PostgreSQL database server logs with severity levels |
| `postgrest` | PostgREST | PostgREST API request/response logs |
| `pooler` | Pooler | Database connection pooler logs |
| `auth` | Auth | Authentication and authorization service logs |
| `storage` | Storage | Object storage operation logs |
| `realtime` | Realtime | WebSocket connection and subscription logs |
| `functions` | Edge Functions | Edge function invocation and execution logs |
| `cron` | Cron | Scheduled job execution logs |

### Severity Levels

For Postgres logs and internal service logs, we support PostgreSQL standard severity levels:

| Level | Color | Description |
|-------|-------|-------------|
| `DEBUG` | Gray | Very detailed debugging information |
| `INFO` | Blue | Routine operational information |
| `NOTICE` | Cyan | Noteworthy but not problematic events |
| `WARNING` | Yellow | Potential issues that don't prevent execution |
| `ERROR` | Orange | Command-aborting errors |
| `FATAL` | Red | Session-aborting errors |
| `PANIC` | Dark Red | Database-wide abort errors |

### Database Schema

```sql
-- Create analytics schema
CREATE SCHEMA IF NOT EXISTS analytics;

-- Main logs table
CREATE TABLE analytics.logs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),

    -- Core fields
    timestamp TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    event_message TEXT,

    -- Request identification
    request_id UUID,

    -- HTTP fields (for API logs)
    method VARCHAR(10),
    path TEXT,
    status_code SMALLINT,

    -- Source and severity
    source VARCHAR(50) NOT NULL,
    severity VARCHAR(10) DEFAULT 'INFO',

    -- User/API key info
    user_id UUID,
    user_agent TEXT,
    apikey TEXT,

    -- Request/Response details
    request_headers JSONB DEFAULT '{}',
    response_headers JSONB DEFAULT '{}',

    -- Timing
    duration_ms INTEGER,

    -- Extended metadata
    metadata JSONB DEFAULT '{}',

    -- Full-text search
    search TSVECTOR,

    -- Constraints
    CONSTRAINT logs_source_check CHECK (source IN (
        'edge', 'postgres', 'postgrest', 'pooler',
        'auth', 'storage', 'realtime', 'functions', 'cron'
    )),
    CONSTRAINT logs_severity_check CHECK (severity IN (
        'DEBUG', 'INFO', 'NOTICE', 'WARNING', 'ERROR', 'FATAL', 'PANIC'
    ))
);

-- Create indexes for common queries
CREATE INDEX idx_logs_timestamp ON analytics.logs (timestamp DESC);
CREATE INDEX idx_logs_source ON analytics.logs (source);
CREATE INDEX idx_logs_severity ON analytics.logs (severity);
CREATE INDEX idx_logs_status_code ON analytics.logs (status_code) WHERE status_code IS NOT NULL;
CREATE INDEX idx_logs_method ON analytics.logs (method) WHERE method IS NOT NULL;
CREATE INDEX idx_logs_request_id ON analytics.logs (request_id) WHERE request_id IS NOT NULL;
CREATE INDEX idx_logs_user_id ON analytics.logs (user_id) WHERE user_id IS NOT NULL;
CREATE INDEX idx_logs_metadata ON analytics.logs USING GIN (metadata);
CREATE INDEX idx_logs_search ON analytics.logs USING GIN (search);

-- Saved queries table
CREATE TABLE analytics.saved_queries (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(255) NOT NULL,
    description TEXT,
    query_params JSONB NOT NULL, -- Stores filter parameters
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

-- Query templates table
CREATE TABLE analytics.query_templates (
    id VARCHAR(50) PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    description TEXT,
    query_params JSONB NOT NULL,
    category VARCHAR(50) -- 'common', 'debugging', 'security', etc.
);

-- Insert default templates
INSERT INTO analytics.query_templates (id, name, description, query_params, category) VALUES
('errors_last_hour', 'Errors in last hour', 'All requests with status >= 400 in the past hour',
 '{"time_range": "1h", "status_min": 400}', 'debugging'),
('slow_requests', 'Slow requests', 'Requests taking longer than 1 second',
 '{"time_range": "24h", "duration_min_ms": 1000}', 'performance'),
('auth_failures', 'Authentication failures', 'Failed authentication attempts',
 '{"time_range": "24h", "source": "auth", "status_min": 400}', 'security'),
('storage_uploads', 'Storage uploads', 'Recent file upload operations',
 '{"time_range": "1h", "source": "storage", "method": "POST"}', 'storage');
```

### API Endpoints

#### List Logs
```
GET /api/logs
Query Parameters:
  - source: string (edge, postgres, auth, storage, etc.)
  - status_min: int (minimum status code)
  - status_max: int (maximum status code)
  - method: string (GET, POST, PUT, DELETE, etc.)
  - path: string (path pattern to search)
  - query: string (full-text search in event_message)
  - from: RFC3339 timestamp
  - to: RFC3339 timestamp
  - time_range: string (1h, 24h, 7d, 30d)
  - limit: int (default 25, max 1000)
  - offset: int

Response:
{
  "logs": [...],
  "total": 150,
  "limit": 25,
  "offset": 0
}
```

#### Get Log by ID
```
GET /api/logs/{id}

Response:
{
  "id": "uuid",
  "timestamp": "2026-01-17T21:16:26Z",
  "event_message": "...",
  "method": "POST",
  "path": "/storage/v1/object/list/dev",
  "status_code": 200,
  "source": "edge",
  "user_agent": "@supabase-infra/mgmt-api/b6fcb46",
  "apikey": "sb_temp_cT... <invalid>",
  "duration_ms": 45,
  "metadata": {...}
}
```

#### Get Log Histogram
```
GET /api/logs/histogram
Query Parameters:
  - source: string
  - from: RFC3339 timestamp
  - to: RFC3339 timestamp
  - time_range: string
  - interval: string (1m, 5m, 1h, 1d)

Response:
{
  "buckets": [
    {"timestamp": "2026-01-17T21:00:00Z", "count": 15},
    {"timestamp": "2026-01-17T21:05:00Z", "count": 23},
    ...
  ],
  "total": 150
}
```

#### List Log Sources (Collections)
```
GET /api/logs/sources

Response:
[
  {"id": "edge", "name": "API Gateway", "description": "HTTP request/response logs"},
  {"id": "postgres", "name": "Postgres", "description": "Database server logs"},
  {"id": "postgrest", "name": "PostgREST", "description": "REST API logs"},
  {"id": "pooler", "name": "Pooler", "description": "Connection pooler logs"},
  {"id": "auth", "name": "Auth", "description": "Authentication logs"},
  {"id": "storage", "name": "Storage", "description": "Object storage logs"},
  {"id": "realtime", "name": "Realtime", "description": "WebSocket connection logs"},
  {"id": "functions", "name": "Edge Functions", "description": "Function invocation logs"},
  {"id": "cron", "name": "Cron", "description": "Scheduled job logs"}
]
```

#### Search Logs
```
POST /api/logs/search
Body:
{
  "source": "edge",
  "status_codes": [200, 201, 400, 500],
  "methods": ["GET", "POST"],
  "path_pattern": "/storage/*",
  "query": "error",
  "from": "2026-01-17T00:00:00Z",
  "to": "2026-01-17T23:59:59Z",
  "limit": 100,
  "offset": 0
}

Response: Same as GET /api/logs
```

#### Saved Queries
```
GET /api/logs/queries           # List saved queries
POST /api/logs/queries          # Create saved query
GET /api/logs/queries/{id}      # Get saved query
PUT /api/logs/queries/{id}      # Update saved query
DELETE /api/logs/queries/{id}   # Delete saved query
```

#### Query Templates
```
GET /api/logs/templates         # List available templates
```

#### Export Logs
```
GET /api/logs/export
Query Parameters:
  - format: json | csv
  - (same filters as GET /api/logs)
```

### Go Types

```go
// store/store.go additions

// LogEntry represents a single log entry
type LogEntry struct {
    ID              string                 `json:"id"`
    Timestamp       time.Time              `json:"timestamp"`
    EventMessage    string                 `json:"event_message"`
    RequestID       *string                `json:"request_id,omitempty"`
    Method          string                 `json:"method,omitempty"`
    Path            string                 `json:"path,omitempty"`
    StatusCode      int                    `json:"status_code,omitempty"`
    Source          string                 `json:"source"`
    UserID          *string                `json:"user_id,omitempty"`
    UserAgent       string                 `json:"user_agent,omitempty"`
    APIKey          string                 `json:"apikey,omitempty"`
    RequestHeaders  map[string]string      `json:"request_headers,omitempty"`
    ResponseHeaders map[string]string      `json:"response_headers,omitempty"`
    DurationMs      int                    `json:"duration_ms,omitempty"`
    Metadata        map[string]interface{} `json:"metadata,omitempty"`
}

// LogFilter represents query parameters for log filtering
type LogFilter struct {
    Source      string     `json:"source,omitempty"`
    StatusMin   int        `json:"status_min,omitempty"`
    StatusMax   int        `json:"status_max,omitempty"`
    Methods     []string   `json:"methods,omitempty"`
    PathPattern string     `json:"path_pattern,omitempty"`
    Query       string     `json:"query,omitempty"`
    From        *time.Time `json:"from,omitempty"`
    To          *time.Time `json:"to,omitempty"`
    TimeRange   string     `json:"time_range,omitempty"` // 1h, 24h, 7d, 30d
    Limit       int        `json:"limit,omitempty"`
    Offset      int        `json:"offset,omitempty"`
}

// LogHistogramBucket represents a single histogram bucket
type LogHistogramBucket struct {
    Timestamp time.Time `json:"timestamp"`
    Count     int       `json:"count"`
}

// SavedQuery represents a user's saved log query
type SavedQuery struct {
    ID          string                 `json:"id"`
    Name        string                 `json:"name"`
    Description string                 `json:"description,omitempty"`
    QueryParams map[string]interface{} `json:"query_params"`
    CreatedAt   time.Time              `json:"created_at"`
    UpdatedAt   time.Time              `json:"updated_at"`
}

// QueryTemplate represents a predefined query template
type QueryTemplate struct {
    ID          string                 `json:"id"`
    Name        string                 `json:"name"`
    Description string                 `json:"description,omitempty"`
    QueryParams map[string]interface{} `json:"query_params"`
    Category    string                 `json:"category,omitempty"`
}

// LogSource represents a log collection type
type LogSource struct {
    ID          string `json:"id"`
    Name        string `json:"name"`
    Description string `json:"description"`
}

// LogsStore defines the interface for log storage operations
type LogsStore interface {
    // Log entries
    CreateLog(ctx context.Context, entry *LogEntry) error
    GetLog(ctx context.Context, id string) (*LogEntry, error)
    ListLogs(ctx context.Context, filter *LogFilter) ([]*LogEntry, int, error)

    // Histogram
    GetHistogram(ctx context.Context, filter *LogFilter, interval string) ([]LogHistogramBucket, error)

    // Saved queries
    CreateSavedQuery(ctx context.Context, query *SavedQuery) error
    GetSavedQuery(ctx context.Context, id string) (*SavedQuery, error)
    ListSavedQueries(ctx context.Context) ([]*SavedQuery, error)
    UpdateSavedQuery(ctx context.Context, query *SavedQuery) error
    DeleteSavedQuery(ctx context.Context, id string) error

    // Templates
    ListQueryTemplates(ctx context.Context) ([]*QueryTemplate, error)
}
```

### Frontend Components

#### LogsExplorerPage Structure

```
┌─────────────────────────────────────────────────────────────────────────┐
│ Logs & Analytics                                          Source: [▼]   │
├──────────────┬──────────────────────────────────────────────────────────┤
│              │ [Search events...] [⟳] [Last hour▼] [Status▼] [Method▼]  │
│  NEW LOGS    │                                                          │
│  Coming Soon │ ┌──────────────────────────────────────────────────────┐ │
│  [Early acc] │ │                   Histogram Chart                    │ │
│              │ │   ▄  ▄█▄                                             │ │
│  Templates   │ │   █  ███                                             │ │
│              │ │ ▄▄█▄▄███▄▄                                           │ │
│ ──────────── │ └──────────────────────────────────────────────────────┘ │
│ COLLECTIONS  │                                                          │
│ > API Gateway│ ┌─────────────────────────────────────────┬────────────┐ │
│   Postgres   │ │ Timestamp     Status  Method  Path      │ Details    │ │
│   PostgREST  │ ├─────────────────────────────────────────┤            │ │
│   Pooler     │ │ 17 Jan 21:16  200     POST   /storage.. │ id: abc... │ │
│   Auth       │ │ 17 Jan 21:16  200     GET    /storage.. │ status:200 │ │
│   Storage    │ │ 17 Jan 21:12  200     DELETE /storage.. │ timestamp  │ │
│   Realtime   │ │ ...                                     │ method     │ │
│   Edge Fns   │ │                                         │ path       │ │
│   Cron       │ │                                         │ metadata   │ │
│ ───────────  │ │                                         │            │ │
│ DB OPERATIONS│ │ [⟲ Load older]  Showing 25 results      │ [Expand]   │ │
│              │ └─────────────────────────────────────────┴────────────┘ │
│ QUERIES      │                                                          │
│ No queries   │                                                          │
│ [Create]     │                                                          │
└──────────────┴──────────────────────────────────────────────────────────┘
```

#### Key Components

1. **LogsSidebar** - Left panel with collections, templates, saved queries
2. **LogsToolbar** - Search, time range, filters
3. **LogsHistogram** - Bar chart showing log volume
4. **LogsTable** - Main log entries table
5. **LogsDetailPanel** - Right panel showing selected log details
6. **SavedQueryModal** - Modal for creating/editing saved queries

### Logging Middleware

The logging middleware captures HTTP requests and responses automatically:

```go
// middleware/logging.go

type LoggingMiddleware struct {
    logsStore LogsStore
    ignorePaths []string // paths to ignore (e.g., /health)
}

func (m *LoggingMiddleware) Handler(next mizu.Handler) mizu.Handler {
    return func(c *mizu.Ctx) error {
        start := time.Now()
        requestID := uuid.New().String()

        // Capture request info before handler
        method := c.Request().Method
        path := c.Request().URL.Path
        userAgent := c.Request().Header.Get("User-Agent")

        // Call handler
        err := next(c)

        // Capture response info after handler
        duration := time.Since(start)
        statusCode := c.Response().StatusCode

        // Determine source based on path
        source := determineSource(path)

        // Create log entry asynchronously
        go m.logsStore.CreateLog(context.Background(), &LogEntry{
            Timestamp:    time.Now(),
            EventMessage: formatEventMessage(method, statusCode, path),
            RequestID:    &requestID,
            Method:       method,
            Path:         path,
            StatusCode:   statusCode,
            Source:       source,
            UserAgent:    userAgent,
            DurationMs:   int(duration.Milliseconds()),
            // ... other fields from context
        })

        return err
    }
}

func determineSource(path string) string {
    switch {
    case strings.HasPrefix(path, "/auth/"):
        return "auth"
    case strings.HasPrefix(path, "/storage/"):
        return "storage"
    case strings.HasPrefix(path, "/rest/"):
        return "postgrest"
    case strings.HasPrefix(path, "/functions/"):
        return "functions"
    case strings.HasPrefix(path, "/realtime/"):
        return "realtime"
    default:
        return "edge"
    }
}
```

### Implementation Plan

#### Phase 1: Backend Infrastructure
1. Add `LogsStore` interface to `store/store.go`
2. Create `store/postgres/logs.go` with PostgreSQL implementation
3. Add schema creation to `store/postgres/store.go`
4. Create logging middleware

#### Phase 2: API Handlers
1. Rewrite `app/web/handler/api/logs.go` with new endpoints
2. Add routes to `app/web/server.go`
3. Wire up logging middleware

#### Phase 3: Frontend
1. Create new components in `app/frontend/src/pages/logs/`
2. Update `app/frontend/src/api/logs.ts` with new API methods
3. Add new types to `app/frontend/src/types/index.ts`
4. Update sidebar navigation

#### Phase 4: Testing
1. Add integration tests for logs API
2. Update e2e tests for new UI
3. Add performance tests for histogram queries

## Testing Strategy

### Unit Tests
- LogsStore methods
- Log filtering logic
- Histogram bucketing

### Integration Tests
- API endpoint responses
- Log ingestion pipeline
- Query performance with large datasets

### E2E Tests
- Page load and rendering
- Collection selection
- Filter interactions
- Histogram display
- Detail panel opening
- Export functionality
- Saved query CRUD

## Success Metrics

1. **Functionality**: All Supabase Logs UI features work
2. **Performance**: Queries return < 500ms for 1M logs
3. **Accuracy**: 100% of requests logged correctly
4. **UX**: UI matches Supabase design 100%

## Future Enhancements

1. Log retention policies (auto-delete after N days)
2. OpenTelemetry integration for distributed tracing
3. Log alerts (notify on error rate spike)
4. Full-text search improvements
5. Query builder UI
6. Log streaming via WebSocket

## References

- [Supabase Logs Documentation](https://supabase.com/docs/guides/telemetry/logs)
- [Supabase Self-Hosting Analytics](https://supabase.com/docs/reference/self-hosting-analytics/introduction)
- [Logflare Architecture](https://github.com/Logflare/logflare)
